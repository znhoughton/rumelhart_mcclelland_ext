---
title: "sae_analysis"
author: "Zachary Houghton"
date: "2025-12-21"
output: html_document
---

```{r setup, include=FALSE}

```

## 

```{r}

library(dplyr)
library(stringr)
library(purrr)
library(readr)
library(tidyr)

INPUT_CSV <- "../Data/sae_latents_long.csv"

MIN_LEN <- 1          # minimum phones in pattern
MIN_WSUP <- 0.7       # minimum activation-weighted support
ALPHA <- 1.25          # length reward exponent
TOP_K <- 50           # patterns per latent

split_phones <- function(x) str_split(x, "\\s+")[[1]]

all_substrings <- function(phones) {
  n <- length(phones)
  out <- character(0)
  for (i in seq_len(n)) {
    for (j in i:n) {
      out <- c(out, paste(phones[i:j], collapse = " "))
    }
  }
  out
}

# Keep patterns that are not "dominated" by a longer one with >= same w_support.
remove_dominated <- function(df) {
  # df must already be sorted descending by length then score
  keep <- logical(nrow(df))
  for (i in seq_len(nrow(df))) {
    pat <- df$pattern[i]
    # if there exists a longer pattern that contains this pattern and has >= same w_support,
    # then the shorter is probably not the real pattern
    longer <- df %>%
      filter(length > df$length[i], w_support >= df$w_support[i]) %>%
      pull(pattern)
    keep[i] <- !any(str_detect(longer, fixed(pat)))
  }
  df[keep, ]
}

df <- read_csv(INPUT_CSV, show_col_types = FALSE) %>%
  mutate(
    phones = map(present_phones, split_phones),
    activation = as.numeric(activation)
  ) %>%
  filter(is.finite(activation), activation > 0)

patterns <- df %>%
  select(latent_id, lemma, activation, phones) %>%
  mutate(substrings = map(phones, all_substrings)) %>%
  unnest(substrings) %>%
  transmute(
    latent_id,
    lemma,
    activation,
    pattern = substrings,
    length = str_count(pattern, " ") + 1
  ) %>%
  filter(length >= MIN_LEN) %>%
  distinct(latent_id, lemma, pattern, length, .keep_all = TRUE) %>%
  group_by(latent_id, pattern, length) %>%
  summarise(
    # total activation mass among words that contain pattern
    act_sum_in_pattern = sum(activation),
    # how many distinct words contain it (still useful to inspect)
    n_verbs = n_distinct(lemma),
    .groups = "drop"
  ) %>%
  group_by(latent_id) %>%
  mutate(
    act_total = sum(df$activation[df$latent_id == first(latent_id)]),  # total activation in latent
    w_support = act_sum_in_pattern / act_total,
    score = w_support * (length ^ ALPHA)
  ) %>%
  ungroup() %>%
  filter(w_support >= MIN_WSUP)

patterns_ranked <- patterns %>%
  group_by(latent_id) %>%
  slice_max(
    order_by = score,
    n = 1,
    with_ties = FALSE
  ) %>%
  ungroup()



```

```{r}
write_csv(patterns_ranked, "../Data/latent_patterns_weighted_length_reward.csv")
```
